as.integer(glm.pred,0,1)
typeof(Default.test$default)
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
No = as.integer(0)
Yes = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
table(glm.pred, Default.test$default)
mean(glm.pred != Default.test$default)
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
No = as.integer(0)
Yes = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep("NO",nrow(Default.test))
glm.pred[glm.probs>.5] = "YES"
# contingency table
table(glm.pred, Default.test$default)
mean(glm.pred != Default.test$default)
is.integer(NO)
No = as.integer(0)
is.integer(NO)
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
table(glm.pred, Default.test$default)
mean(glm.pred != Default.test$default)
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
GLM.PRED
glm.pred
mean(glm.pred == Default.test$default)
}
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
for(i in 1:3){
set.seed(i)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
table(glm.pred, Default.test$default)
}
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
for(i in 1:3){
set.seed(i)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
x = table(glm.pred, Default.test$default)
print(x)
}
####################################################################
# Implement Q5-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
x = table(glm.pred, Default.test$default)
print(x)
####################################################################
# Implement Q5-c from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
for(i in 1:3){
set.seed(i)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
x = table(glm.pred, Default.test$default)
print(x)
}
####################################################################
# Implement Q5-d from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income+student, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
x = table(glm.pred, Default.test$default)
print(x)
x = seq(10000)
x
x = seq(10000)
plot(x,1-(1-1/x)^x)
x = seq(10000)
y<-1-(1-1/x)^x
plot(x,y)
?plot
x = seq(10000)
y<-1-(1-1/x)^x
plot(x,y,ylim=range(0,1))
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
store =rep (NA , 10000)
for (i in 1:10000) {
store [i]= sum ( sample (1:100 , rep =TRUE) ==4) >0
}
mean( store )
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
install.packages("leap")
install.packages("leaps")
data <- data.frame(x,y)
library(leaps)
data
?I
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
library(leaps)
data <- data.frame(x,y)
regfit.full= regsubsets (y~x+x^2+x^3+x^4+x^5+x^6+x^7+x^8+x^9+x^10,data=data,nvmax=10)
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
library(leaps)
data <- data.frame(x,x^2,x^3,x^4,y)
data
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
library(leaps)
data <- data.frame(x,x^2,x^3,x^4,x^5,x^6,x^7,x^8,x^9,x^10,y)
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
library(leaps)
data <- data.frame(x,x^2,x^3,x^4,x^5,x^6,x^7,x^8,x^9,x^10,y)
data
names(data)
####################################################################
# Implement Q6-b from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
x <- rnorm(100)
eps <- rnorm(100)
b0 = 3
b1 = 2
b2 = 5
b3 = 1
y <- b0 + b1*x+b2*(x^2)+b3*(x^3)+eps
library(leaps)
data <- data.frame(x,x^2,x^3,x^4,x^5,x^6,x^7,x^8,x^9,x^10,y)
regfit.full= regsubsets (y~x+x.2+x.3+x.4+x.5+x.6+x.7+x.8+x.9+x.10,data=data,nvmax=10)
summary(regfit.full)
par(mfrow =c(2 ,2))
#plot the cp
plot(reg.summary$cp ,xlab =" Number of Variables ", ylab =" Cp",
type=’l’)
which.min(reg.summary$cp )
reg.summary = summary(regfit.full)
par(mfrow =c(2 ,2))
#plot the cp
plot(reg.summary$cp ,xlab =" Number of Variables ", ylab =" Cp",
type=’l’)
which.min(reg.summary$cp )
#plot the cp
plot(reg.summary$cp ,xlab =" Number of Variables ", ylab =" Cp",
type='l')
which.min(reg.summary$cp )
plot(reg.summary$bic, xlab =" Number of Variables ", ylab =" BIC ",
type='l')
plot(reg.summary$adjr2 ,xlab =" Number of Variables ",
ylab =" Adjusted R^2 ", type ="l")
coef(regfit.full, 3)
setwd("C:/Users/czx/Google Drive/CSC 591(Foundation of Data Science)/hw4/New folder")
####################################################################
# Implement an R program for PCA based Eigenface Generation        #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(pixmap) # read the .pgm image
setwd("faces-corrected/faces-corrected/")
options(warn=-1)
file_list <- list.files()
for(file in file_list){
temp  <- read.pnm(file)
temp_vector <- as.vector(t(temp@grey))
if(!exists("A")){
A<- temp_vector
image_row <- nrow(temp@grey)
image_col <- ncol(temp@grey)
}else{
A <- cbind(A,temp_vector)
}
}
# compute the mean for each row of the matrix
row_mean <- as.vector(rowMeans(A))
for(i in 1:nrow(A)){
A[i,]<-A[i,]-row_mean[i]
}
# compute the A'*A
mat <- t(A) %*% A
#eigenvectors for the A'*A matrix
eig <- eigen(mat)
# convert the eigenvectors of the A'*A matrix to A*A' matrix
ori_eig <- A %*% eig$vectors
for(i in 1:10){
x11()
eigenface <- matrix(ori_eig[,i],image_col,image_row)
eigenface = t(eigenface)
image <- pixmapGrey(eigenface)
plot(image,main=paste('The ',i,'th eigenface image'))
}
####################################################################
# Implement Q5-d from the textbook                                 #
# Hw4 of CSC 591(Foundation of Data Science)                       #
# Author: Zexi chen(Unity ID: zchen22)                             #
####################################################################
rm(list=ls(all=T))
library(ISLR)
# the database is attached to the R search path
attach(Default)
# check the defaulted value of the variable
contrasts(default)
set.seed(1)
train = sample(nrow(Default),nrow(Default)/2)
Default.train = Default[train,]
Default.test = Default[-train,]
# create the logistic model to predict the default value based on the balance variable
glm.fit <- glm(default~balance+income+student, data=Default.train, family=binomial)
summary(glm.fit)
# use the training dataset the fit the model
glm.probs = predict(glm.fit,Default.test,type="response")
NO = as.integer(0)
YES = as.integer(1)
# assign labelsbased on the calculated probability
glm.pred = rep(NO,nrow(Default.test))
glm.pred[glm.probs>.5] = YES
# contingency table
x = table(glm.pred, Default.test$default)
print(x)
